{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fa42c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.9.18)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from pygame import mixer\n",
    "import urllib.request\n",
    "from http.client import IncompleteRead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cdc8a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize pygame mixer for sound alerts\n",
    "mixer.init()\n",
    "sound = mixer.Sound('car-lock.wav')\n",
    "\n",
    "# Load face and eye cascades\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_eye.xml\")\n",
    "\n",
    "# Load eye detection model\n",
    "model = load_model(r'C:\\Users\\LAPTOP\\Desktop\\CameraWebServer\\python code\\cnnCat2.h5')\n",
    "lbl = ['Close', 'Open']\n",
    "\n",
    "# URL of the ESP32 cam stream\n",
    "url = 'http://192.168.43.109/cam-lo.jpg'\n",
    "cv2.namedWindow(\"live Cam Testing\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "# Create a VideoCapture object\n",
    "cap = cv2.VideoCapture(url)\n",
    "\n",
    "# Check if the IP camera stream is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Failed to open the IP camera stream\")\n",
    "    exit()\n",
    "\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "score = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Read a frame from the IP camera stream\n",
    "        img_resp = urllib.request.urlopen(url)\n",
    "        imgnp = np.array(bytearray(img_resp.read()), dtype=np.uint8)\n",
    "        im = cv2.imdecode(imgnp, -1)\n",
    "\n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the frame\n",
    "        faces = face_cascade.detectMultiScale(gray, minNeighbors=3, scaleFactor=1.1, minSize=(25, 25))\n",
    "        eyes = eye_cascade.detectMultiScale(gray, minNeighbors=1, scaleFactor=1.1)\n",
    "\n",
    "        cv2.rectangle(im, (0, im.shape[0] - 50), (200, im.shape[0]), (0, 0, 0), thickness=cv2.FILLED)\n",
    "\n",
    "        for (x, y, w, h) in eyes:\n",
    "            eye = im[y:y + h, x:x + w]\n",
    "\n",
    "            # Convert the eye to grayscale\n",
    "            eye_gray = cv2.cvtColor(eye, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Resize the eye to (24, 24)\n",
    "            eye_gray = cv2.resize(eye_gray, (24, 24))\n",
    "\n",
    "            # Normalize the pixel values to be between 0 and 1\n",
    "            eye_gray = eye_gray / 255.0\n",
    "\n",
    "            # Reshape the eye to match the expected input shape of the model\n",
    "            eye_gray = np.reshape(eye_gray, (1, 24, 24, 1))\n",
    "\n",
    "            # Make a prediction using the model\n",
    "            prediction = model.predict(eye_gray)\n",
    "\n",
    "            # Rest of your code...\n",
    "            # Condition for Close\n",
    "            if prediction[0][0] > 0.30:\n",
    "                cv2.putText(im, \"Closed\", (10, im.shape[0] - 20), font, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "                cv2.putText(im, 'Score:' + str(score), (100, im.shape[0] - 20), font, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "                score = score + 1\n",
    "                if score > 20:\n",
    "                    try:\n",
    "                        sound.play()\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "            # Condition for Open\n",
    "            elif prediction[0][1] > 0.70:\n",
    "                score = score - 1\n",
    "                if score < 0:\n",
    "                    score = 0\n",
    "                cv2.putText(im, \"Open\", (10, im.shape[0] - 20), font, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "                cv2.putText(im, 'Score:' + str(score), (100, im.shape[0] - 20), font, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        # Display the processed frame\n",
    "        cv2.imshow('live Cam Testing', im)\n",
    "\n",
    "        # Check for the 'q' key to exit\n",
    "        key = cv2.waitKey(5)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    except IncompleteRead:\n",
    "        # Handle IncompleteRead error by continuing with the next iteration\n",
    "        pass\n",
    "\n",
    "# Release the camera and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bb6712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1eac79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f869e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
